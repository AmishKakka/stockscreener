{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import pd, time\n",
    "import numpy as np\n",
    "import yfinance as source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs for the NASDAQ Trader Symbol Directory files\n",
    "# List is updated everyday.\n",
    "nasdaq_url = \"ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt\"\n",
    "# other_url = \"ftp://ftp.nasdaqtrader.com/SymbolDirectory/otherlisted.txt\"\n",
    "\n",
    "# Load NASDAQ-listed stocks\n",
    "nasdaq_data = pd.read_csv(nasdaq_url, sep=\"|\")\n",
    "# Remove the last row (footer info)\n",
    "nasdaq_data = nasdaq_data[:-1]\n",
    "\n",
    "# # Load other-listed stocks (including NYSE, AMEX, etc.)\n",
    "# other_data = pd.read_csv(other_url, sep=\"|\")\n",
    "# # Filter for NYSE stocks\n",
    "# nyse_stocks = other_data[other_data[\"Exchange\"] == \"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Filter for companies that are not bankrupt, delisted, etc.\n",
    "normal_cmps = nasdaq_data.where(nasdaq_data[\"Financial Status\"] == \"N\").dropna()\n",
    "normal_cmps.index = range(len(normal_cmps))\n",
    "normal_cmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_tickers = normal_cmps[[\"Symbol\", \"Security Name\"]]\n",
    "nasdaq_tickers.loc[:, \"Exchange\"] = \"NASDAQ\"\n",
    "nasdaq_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = ['symbol', 'shortName', 'currency', 'previousClose', 'open', 'dayLow', 'dayHigh', 'regularMarketPreviousClose',\n",
    "               'regularMarketOpen', 'regularMarketDayLow', 'regularMarketDayHigh', 'dividendRate', 'dividendYield',\n",
    "              'fiveYearAvgDividendYield', 'beta', 'trailingPE', 'forwardPE', 'volume',  'marketCap',\n",
    "              'fiftyTwoWeekLow', 'fiftyTwoWeekHigh', 'priceToSalesTrailing12Months', 'fiftyDayAverage', \n",
    "              'twoHundredDayAverage', 'profitMargins', 'bookValue', 'priceToBook', 'earningsQuarterlyGrowth', \n",
    "              'netIncomeToCommon', 'trailingEps', 'forwardEps', 'enterpriseToRevenue', 'enterpriseToEbitda', '52WeekChange',\n",
    "              'ebitda', 'totalDebt', 'quickRatio', 'currentRatio', 'totalRevenue', 'debtToEquity', 'revenuePerShare', 'returnOnAssets', \n",
    "              'returnOnEquity', 'grossProfits', 'freeCashflow', 'operatingCashflow', 'earningsGrowth', 'revenueGrowth', 'grossMargins', \n",
    "              'ebitdaMargins', 'operatingMargins', 'trailingPegRatio']\n",
    "\n",
    "data = []\n",
    "def download_data(stocks):\n",
    "    stk = source.Tickers(\" \".join(stocks))\n",
    "    for ticker in stocks:\n",
    "        try:\n",
    "            stock_info = stk.tickers[ticker].info\n",
    "            row = {key: stock_info.get(key, None) for key in data_points}\n",
    "            data.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "m = len(list(nasdaq_tickers[\"Symbol\"]))\n",
    "\n",
    "# Running below commented lines will fetch data for all the stocks in the NASDAQ list and uncomment if fetching\n",
    "# data for first time.\n",
    "for idx in range(0, m, batch_size):\n",
    "    download_data(list(nasdaq_tickers[\"Symbol\"][idx:idx+batch_size]))\n",
    "    time.sleep(5)\n",
    "print(f\"Done fetching data for {len(data)} stocks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksData = [i for i in data if i!=None]\n",
    "print(f\"{len(stocksData)} stocks data fetched!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now, we have to standarize the data for some of the columns and remove duplicates***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksData_df = pd.DataFrame(stocksData, columns=data_points)\n",
    "stocksData_df = stocksData_df.dropna(subset=[\"symbol\"])\n",
    "stocksData_df = stocksData_df.replace([np.nan], 0.0)\n",
    "stocksData_df.columns = [i.capitalize() for i in stocksData_df.columns]\n",
    "stocksData_df['Marketcap'] = stocksData_df['Marketcap']/(10e8) # Converting marketcap in order of 100 million\n",
    "stocksData_df['Returnonequity'] = stocksData_df['Returnonequity']*100 # Converting to percentage\n",
    "stocksData_df['Earningsgrowth'] = stocksData_df['Earningsgrowth']*100 # Converting to percentage\n",
    "stocksData_df['Revenuegrowth'] = stocksData_df['Revenuegrowth']*100 # Converting to percentage\n",
    "stocksData_df['Profitmargins'] = stocksData_df['Profitmargins']*100 # Converting to percentage\n",
    "stocksData_df['Ebitdamargins'] = stocksData_df['Ebitdamargins']*100 # Converting to percentage\n",
    "stocksData_df['Totalrevenue'] = stocksData_df['Totalrevenue']/(10e8) # Converting total revenue in order of 100 million\n",
    "stocksData_df['Grossprofits'] = stocksData_df['Grossprofits']/(10e8) # Converting gross profits in order of 100 million\n",
    "stocksData_df['Freecashflow'] = stocksData_df['Freecashflow']/(10e8) # Converting free cash flow in order of 100 million\n",
    "stocksData_df['Operatingcashflow'] = stocksData_df['Operatingcashflow']/(10e8) # Converting free cash flow in order of 100 million\n",
    "stocksData_df = stocksData_df[stocksData_df['Currency']!='0.0']\n",
    "stocksData_df = stocksData_df.round(2)\n",
    "# Drop duplicates based on the Symbol column, keeping the first occurrence\n",
    "stocksData_df = stocksData_df.drop_duplicates(subset=\"Symbol\", keep=\"first\")\n",
    "stocksData_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "stocksData_df.to_csv(\"stocksData.csv\", index=False)\n",
    "print(\"Saved data to csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stocksData.csv\")\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(\"Column:\", col, df[col].idxmax(), df.loc[df[col].idxmax()]['Symbol'], df[col].idxmin(), df.loc[df[col].idxmin()]['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"stocksData.csv\", index=False)\n",
    "print(\"Saved data to csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
